#!/usr/bin/env python3
"""
AlphaSeeker ä¸€é”®å¯åŠ¨è„šæœ¬
=======================

è‡ªåŠ¨è§£å†³æ‰€æœ‰é—®é¢˜å¹¶å¯åŠ¨ç³»ç»Ÿ

ä½œè€…: AlphaSeeker Team
ç‰ˆæœ¬: 1.0.0
"""

import os
import sys
import subprocess
import time
import signal
import socket
from pathlib import Path

def check_port_available(port):
    """æ£€æŸ¥ç«¯å£æ˜¯å¦å¯ç”¨"""
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(1)
        result = sock.connect_ex(('127.0.0.1', port))
        sock.close()
        return result != 0
    except:
        return False

def install_dependencies():
    """å®‰è£…ä¾èµ–åŒ…"""
    print("ğŸ“¦ å®‰è£…ä¾èµ–åŒ…...")
    dependencies = [
        'fastapi', 'uvicorn', 'lightgbm', 'pandas', 
        'numpy', 'scikit-learn', 'requests', 'pyyaml',
        'ccxt', 'psutil', 'aiofiles'
    ]
    
    for dep in dependencies:
        try:
            result = subprocess.run(
                [sys.executable, '-m', 'pip', 'install', dep],
                capture_output=True, text=True, timeout=30
            )
            if result.returncode == 0:
                print(f"âœ… {dep}")
            else:
                print(f"âŒ {dep} - {result.stderr}")
        except Exception as e:
            print(f"âŒ {dep} - {e}")

def setup_environment():
    """è®¾ç½®ç¯å¢ƒ"""
    print("ğŸ”§ è®¾ç½®ç¯å¢ƒ...")
    
    # åˆ›å»ºå¿…è¦ç›®å½•
    dirs = ['data', 'logs', 'models', 'cache', 'config']
    for dir_name in dirs:
        os.makedirs(dir_name, exist_ok=True)
        print(f"ğŸ“ åˆ›å»ºç›®å½•: {dir_name}")
    
    # åˆ›å»º.envæ–‡ä»¶
    env_content = """# AlphaSeeker ç¯å¢ƒé…ç½®
ALPHA_SEEKER_HOST=0.0.0.0
ALPHA_SEEKER_PORT=8000
ALPHA_SEEKER_DEBUG=false
LLM_PROVIDER=ollama
LLM_BASE_URL=http://localhost:11434
LLM_MODEL_NAME=llama2:13b
LLM_TIMEOUT=10.0
MAX_CONCURRENT_TASKS=32
BATCH_SIZE=100
ENABLE_CACHE=true
"""
    
    with open('.env', 'w', encoding='utf-8') as f:
        f.write(env_content)
    print("âœ… åˆ›å»º .env æ–‡ä»¶")

def start_ollama():
    """å¯åŠ¨OllamaæœåŠ¡"""
    print("ğŸ¤– å¯åŠ¨OllamaæœåŠ¡...")
    try:
        # æ£€æŸ¥Ollamaæ˜¯å¦å·²è¿è¡Œ
        response = subprocess.run(
            ['curl', '-s', 'http://localhost:11434/api/tags'],
            capture_output=True, timeout=5
        )
        
        if response.returncode == 0:
            print("âœ… OllamaæœåŠ¡å·²è¿è¡Œ")
            return True
    except:
        pass
    
    print("âš ï¸  OllamaæœåŠ¡æœªè¿è¡Œ")
    print("è¯·æ‰‹åŠ¨å¯åŠ¨Ollama:")
    print("1. ç»ˆç«¯1: ollama serve")
    print("2. ç»ˆç«¯2: ollama run llama2:13b")
    return False

def start_alphaseeker():
    """å¯åŠ¨AlphaSeeker"""
    print("ğŸš€ å¯åŠ¨AlphaSeekerç³»ç»Ÿ...")
    
    # æ£€æŸ¥ç«¯å£
    if not check_port_available(8000):
        print("âŒ ç«¯å£8000è¢«å ç”¨ï¼Œè¯·å…ˆé‡Šæ”¾ç«¯å£")
        return False
    
    try:
        print("\n" + "="*50)
        print("ğŸš€ AlphaSeeker å¯åŠ¨ä¸­...")
        print("="*50)
        print("Webç•Œé¢: http://localhost:8000")
        print("APIæ–‡æ¡£: http://localhost:8000/docs")
        print("æŒ‰ Ctrl+C åœæ­¢ç³»ç»Ÿ")
        print("="*50)
        
        # å¯åŠ¨ç³»ç»Ÿ
        subprocess.run([sys.executable, "main_integration.py"])
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç³»ç»Ÿå·²åœæ­¢")
    except Exception as e:
        print(f"å¯åŠ¨å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ AlphaSeeker ä¸€é”®å¯åŠ¨è„šæœ¬")
    print("=" * 60)
    
    # è®¾ç½®å·¥ä½œç›®å½•
    script_dir = Path(__file__).parent
    os.chdir(script_dir)
    
    # å®‰è£…ä¾èµ–
    print("\n1. å®‰è£…ä¾èµ–åŒ…:")
    install_dependencies()
    
    # è®¾ç½®ç¯å¢ƒ
    print("\n2. è®¾ç½®ç¯å¢ƒ:")
    setup_environment()
    
    # æ£€æŸ¥Ollama
    print("\n3. æ£€æŸ¥LLMæœåŠ¡:")
    start_ollama()
    
    # å¯åŠ¨ç³»ç»Ÿ
    print("\n4. å¯åŠ¨ç³»ç»Ÿ:")
    start_alphaseeker()
    
    print("\n" + "=" * 60)
    print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨AlphaSeeker!")
    print("=" * 60)

if __name__ == "__main__":
    main()